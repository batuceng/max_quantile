{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   add_remove_every_n_epoch  proto_split_density_threshold  \\\n",
      "2                     99999                          0.001   \n",
      "5                     99999                          0.001   \n",
      "\n",
      "   proto_remove_density_threshold  repulsion_loss_margin  cov_value_mean  \\\n",
      "2                          0.0001                  0.001        0.905581   \n",
      "5                          0.0001                  0.010        0.905581   \n",
      "\n",
      "   PINAW_value_mean  \n",
      "2          2.222284  \n",
      "5          2.222284  \n",
      "   add_remove_every_n_epoch  proto_split_density_threshold  \\\n",
      "1                     99999                          0.001   \n",
      "4                     99999                          0.001   \n",
      "\n",
      "   proto_remove_density_threshold  repulsion_loss_margin  cov_value_mean  \\\n",
      "1                          0.0001                  0.001        0.497986   \n",
      "4                          0.0001                  0.010        0.497986   \n",
      "\n",
      "   PINAW_value_mean  \n",
      "1          0.597663  \n",
      "4          0.597663  \n",
      "   add_remove_every_n_epoch  proto_split_density_threshold  \\\n",
      "6                     99999                          0.001   \n",
      "\n",
      "   proto_remove_density_threshold  repulsion_loss_margin  cov_value_mean  \\\n",
      "6                          0.0001                    0.1        0.095972   \n",
      "\n",
      "   PINAW_value_mean  \n",
      "6          0.116265  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = 'bike_sharing.csv'  # Update with your actual path\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Process the 'cov_value' and 'PINAW_value' columns\n",
    "df['cov_value'] = pd.to_numeric(df['cov_value'], errors='coerce')\n",
    "df['PINAW_value'] = pd.to_numeric(df['PINAW_value'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'cov_value' or 'PINAW_value'\n",
    "df = df.dropna(subset=['cov_value', 'PINAW_value'])\n",
    "\n",
    "# Add a 'coverage_level' column based on the order of results\n",
    "df['result_index'] = df.groupby(['add_remove_every_n_epoch', 'proto_split_density_threshold',\n",
    "                                 'proto_remove_density_threshold', 'repulsion_loss_margin',\n",
    "                                 'seed']).cumcount()\n",
    "\n",
    "# Map result_index to coverage levels\n",
    "coverage_level_mapping = {0: 90, 1: 50, 2: 10}\n",
    "df['coverage_level'] = df['result_index'].map(coverage_level_mapping)\n",
    "\n",
    "# Define hyperparameter columns\n",
    "hyperparameter_cols = ['add_remove_every_n_epoch', 'proto_split_density_threshold',\n",
    "                       'proto_remove_density_threshold', 'repulsion_loss_margin']\n",
    "\n",
    "group_cols = hyperparameter_cols + ['coverage_level']\n",
    "\n",
    "# Compute the average and standard deviation for each hyperparameter setting across seeds\n",
    "grouped = df.groupby(group_cols).agg({\n",
    "    'cov_value': ['mean', 'std'],\n",
    "    'PINAW_value': ['mean', 'std'],\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "grouped.columns = ['_'.join(col).strip('_') for col in grouped.columns.values]\n",
    "\n",
    "# Now, define the function to find the best hyperparameters\n",
    "def find_best_hyperparameters(grouped_df, coverage_target, tolerance=5):\n",
    "    # Calculate the acceptable coverage range\n",
    "    min_acceptable_coverage = (coverage_target - tolerance) / 100   \n",
    "    max_acceptable_coverage = (coverage_target + tolerance) / 100\n",
    "\n",
    "    # Filter for the desired coverage level\n",
    "    coverage_df = grouped_df[grouped_df['coverage_level'] == coverage_target]\n",
    "\n",
    "    # Filter hyperparameters within the acceptable coverage range\n",
    "    acceptable_df = coverage_df[\n",
    "        (coverage_df['cov_value_mean'] >= min_acceptable_coverage) &\n",
    "        (coverage_df['cov_value_mean'] <= max_acceptable_coverage)\n",
    "    ]\n",
    "\n",
    "    if acceptable_df.empty:\n",
    "        print(f\"No hyperparameter settings found within {tolerance}% tolerance for {coverage_target}% coverage.\")\n",
    "        return None\n",
    "\n",
    "    # Find the hyperparameter setting(s) with the minimum PINAW_value_mean\n",
    "    min_pinaw = acceptable_df['PINAW_value_mean'].min()\n",
    "    best_settings = acceptable_df[acceptable_df['PINAW_value_mean'] == min_pinaw]\n",
    "\n",
    "    return best_settings\n",
    "\n",
    "# Find best hyperparameters for each coverage level\n",
    "best_settings_90 = find_best_hyperparameters(grouped, 90, tolerance=5)\n",
    "best_settings_50 = find_best_hyperparameters(grouped, 50, tolerance=5)\n",
    "best_settings_10 = find_best_hyperparameters(grouped, 10, tolerance=5)\n",
    "\n",
    "# Print the best hyperparameter settings\n",
    "# print(\"Best hyperparameters for 90% coverage level:\")\n",
    "print(best_settings_90[hyperparameter_cols + ['cov_value_mean', 'PINAW_value_mean']])\n",
    "\n",
    "# print(\"\\nBest hyperparameters for 50% coverage level:\")\n",
    "print(best_settings_50[hyperparameter_cols + ['cov_value_mean', 'PINAW_value_mean']])\n",
    "\n",
    "# print(\"\\nBest hyperparameters for 10% coverage level:\")\n",
    "print(best_settings_10[hyperparameter_cols + ['cov_value_mean', 'PINAW_value_mean']])\n",
    "\n",
    "# Analyze the influence of each hyperparameter on the results\n",
    "# def analyze_hyperparameter_influence(grouped_df):\n",
    "#     # Ensure hyperparameters are numeric\n",
    "#     analysis_df = grouped_df.copy()\n",
    "#     for col in hyperparameter_cols:\n",
    "#         analysis_df[col] = pd.to_numeric(analysis_df[col], errors='coerce')\n",
    "\n",
    "#     # Drop any rows with NaN hyperparameters\n",
    "#     analysis_df = analysis_df.dropna(subset=hyperparameter_cols)\n",
    "\n",
    "#     # Compute the correlation matrix\n",
    "#     corr_matrix = analysis_df[hyperparameter_cols + ['cov_value_mean', 'PINAW_value_mean']].corr()\n",
    "\n",
    "#     print(\"\\nCorrelation matrix between hyperparameters and PINAW_value_mean:\")\n",
    "#     print(corr_matrix['PINAW_value_mean'])\n",
    "\n",
    "#     print(\"\\nCorrelation matrix between hyperparameters and cov_value_mean:\")\n",
    "#     print(corr_matrix['cov_value_mean'])\n",
    "\n",
    "# Call the analysis function\n",
    "# analyze_hyperparameter_influence(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9,0.014\n",
      "1.0,0.061\n",
      "0.51,0.015\n",
      "0.51,0.034\n",
      "0.095,0.0098\n",
      "0.12,0.011\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = 'meps19.csv'  # Update with your actual path\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Process the 'cov_value' and 'PINAW_value' columns\n",
    "df['cov_value'] = pd.to_numeric(df['cov_value'], errors='coerce')\n",
    "df['PINAW_value'] = pd.to_numeric(df['PINAW_value'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'cov_value' or 'PINAW_value'\n",
    "df = df.dropna(subset=['cov_value', 'PINAW_value'])\n",
    "\n",
    "# Add a 'coverage_level' column based on the order of results\n",
    "df['result_index'] = df.groupby(['add_remove_every_n_epoch', 'proto_split_density_threshold',\n",
    "                                 'proto_remove_density_threshold', 'repulsion_loss_margin',\n",
    "                                 'seed']).cumcount()\n",
    "\n",
    "# Map result_index to coverage levels\n",
    "coverage_level_mapping = {0: 90, 1: 50, 2: 10}\n",
    "df['coverage_level'] = df['result_index'].map(coverage_level_mapping)\n",
    "\n",
    "# Define hyperparameter columns\n",
    "hyperparameter_cols = ['add_remove_every_n_epoch', 'proto_split_density_threshold',\n",
    "                       'proto_remove_density_threshold', 'repulsion_loss_margin']\n",
    "\n",
    "group_cols = hyperparameter_cols + ['coverage_level']\n",
    "\n",
    "# Compute the average and standard deviation for each hyperparameter setting across seeds\n",
    "grouped = df.groupby(group_cols).agg({\n",
    "    'cov_value': ['mean', 'std'],\n",
    "    'PINAW_value': ['mean', 'std'],\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "grouped.columns = ['_'.join(col).strip('_') for col in grouped.columns.values]\n",
    "\n",
    "# Now, define the function to find the best hyperparameters\n",
    "def find_best_hyperparameters(grouped_df, coverage_target, tolerance=5):\n",
    "    # Calculate the acceptable coverage range\n",
    "    min_acceptable_coverage = (coverage_target - tolerance) / 100   \n",
    "    max_acceptable_coverage = (coverage_target + tolerance) / 100\n",
    "\n",
    "    # Filter for the desired coverage level\n",
    "    coverage_df = grouped_df[grouped_df['coverage_level'] == coverage_target]\n",
    "\n",
    "    # Filter hyperparameters within the acceptable coverage range\n",
    "    acceptable_df = coverage_df[\n",
    "        (coverage_df['cov_value_mean'] >= min_acceptable_coverage) &\n",
    "        (coverage_df['cov_value_mean'] <= max_acceptable_coverage)\n",
    "    ]\n",
    "\n",
    "    if acceptable_df.empty:\n",
    "        print(f\"No hyperparameter settings found within {tolerance}% tolerance for {coverage_target}% coverage.\")\n",
    "        return None\n",
    "\n",
    "    # Find the hyperparameter setting(s) with the minimum PINAW_value_mean\n",
    "    min_pinaw = acceptable_df['PINAW_value_mean'].min()\n",
    "    best_settings = acceptable_df[acceptable_df['PINAW_value_mean'] == min_pinaw]\n",
    "\n",
    "    return best_settings\n",
    "\n",
    "# Find best hyperparameters for each coverage level\n",
    "best_settings_90 = find_best_hyperparameters(grouped, 90, tolerance=5)\n",
    "best_settings_50 = find_best_hyperparameters(grouped, 50, tolerance=5)\n",
    "best_settings_10 = find_best_hyperparameters(grouped, 10, tolerance=5)\n",
    "\n",
    "\n",
    "\n",
    "# Print the best hyperparameter settings\n",
    "# print(\"Best hyperparameters for 90% coverage level:\")\n",
    "if best_settings_90 is not None:\n",
    "    # print(best_settings_90[hyperparameter_cols + ['cov_value_mean', 'cov_value_std', 'PINAW_value_mean', 'PINAW_value_std']])\n",
    "    \n",
    "    cov_value_mean = best_settings_90['cov_value_mean'].values[0]\n",
    "    cov_value_std = best_settings_90['cov_value_std'].values[0]\n",
    "\n",
    "    pinaw_value_mean = best_settings_90['PINAW_value_mean'].values[0]\n",
    "    pinaw_value_std = best_settings_90['PINAW_value_std'].values[0]\n",
    "\n",
    "    # Printing the values in the required format\n",
    "    print(f\"{cov_value_mean:.2},{cov_value_std:.2}\")\n",
    "    print(f\"{pinaw_value_mean:.2},{pinaw_value_std:.2}\")\n",
    "else:\n",
    "    print(\"No best settings found for 90% coverage level.\")\n",
    "\n",
    "# print(\"\\nBest hyperparameters for 50% coverage level:\")\n",
    "if best_settings_50 is not None:\n",
    "    # print(best_settings_50[hyperparameter_cols + ['cov_value_mean', 'cov_value_std', 'PINAW_value_mean', 'PINAW_value_std']])\n",
    "    cov_value_mean = best_settings_50['cov_value_mean'].values[0]\n",
    "    cov_value_std = best_settings_50['cov_value_std'].values[0]\n",
    "\n",
    "    pinaw_value_mean = best_settings_50['PINAW_value_mean'].values[0]\n",
    "    pinaw_value_std = best_settings_50['PINAW_value_std'].values[0]\n",
    "\n",
    "    # Printing the values in the required format\n",
    "    print(f\"{cov_value_mean:.2},{cov_value_std:.2}\")\n",
    "    print(f\"{pinaw_value_mean:.2},{pinaw_value_std:.2}\")\n",
    "else:\n",
    "    print(\"No best settings found for 50% coverage level.\")\n",
    "\n",
    "# print(\"\\nBest hyperparameters for 10% coverage level:\")\n",
    "if best_settings_10 is not None:\n",
    "    # print(best_settings_10[hyperparameter_cols + ['cov_value_mean', 'cov_value_std', 'PINAW_value_mean', 'PINAW_value_std']])\n",
    "    \n",
    "    cov_value_mean = best_settings_10['cov_value_mean'].values[0]\n",
    "    cov_value_std = best_settings_10['cov_value_std'].values[0]\n",
    "\n",
    "    pinaw_value_mean = best_settings_10['PINAW_value_mean'].values[0]\n",
    "    pinaw_value_std = best_settings_10['PINAW_value_std'].values[0]\n",
    "\n",
    "    # Printing the values in the required format\n",
    "    print(f\"{cov_value_mean:.2},{cov_value_std:.2}\")\n",
    "    print(f\"{pinaw_value_mean:.2},{pinaw_value_std:.2}\")\n",
    "else:\n",
    "    print(\"No best settings found for 10% coverage level.\")\n",
    "\n",
    "# # Analyze the influence of each hyperparameter on the results\n",
    "# def analyze_hyperparameter_influence(grouped_df):\n",
    "#     # Ensure hyperparameters are numeric\n",
    "#     analysis_df = grouped_df.copy()\n",
    "#     for col in hyperparameter_cols:\n",
    "#         analysis_df[col] = pd.to_numeric(analysis_df[col], errors='coerce')\n",
    "\n",
    "#     # Drop any rows with NaN hyperparameters\n",
    "#     analysis_df = analysis_df.dropna(subset=hyperparameter_cols)\n",
    "\n",
    "#     # Compute the correlation matrix\n",
    "#     corr_matrix = analysis_df[hyperparameter_cols + ['cov_value_mean', 'PINAW_value_mean']].corr()\n",
    "\n",
    "#     print(\"\\nCorrelation matrix between hyperparameters and PINAW_value_mean:\")\n",
    "#     print(corr_matrix['PINAW_value_mean'])\n",
    "\n",
    "#     print(\"\\nCorrelation matrix between hyperparameters and cov_value_mean:\")\n",
    "#     print(corr_matrix['cov_value_mean'])\n",
    "\n",
    "# # Call the analysis function\n",
    "# analyze_hyperparameter_influence(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91, 0.04 (0.9)\n",
      "1.19, 0.13 (0.9)\n",
      "0.53, 0.05 (0.5)\n",
      "0.41, 0.06 (0.5)\n",
      "0.13, 0.04 (0.1)\n",
      "0.06, 0.01 (0.1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = 'concrete.csv'  # Update with your actual path\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Process the 'cov_value' and 'PINAW_value' columns\n",
    "df['cov_value'] = pd.to_numeric(df['cov_value'], errors='coerce')\n",
    "df['PINAW_value'] = pd.to_numeric(df['PINAW_value'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'cov_value' or 'PINAW_value'\n",
    "df = df.dropna(subset=['cov_value', 'PINAW_value'])\n",
    "\n",
    "# Add a 'result_index' column based on the order of results\n",
    "df['result_index'] = df.groupby(['add_remove_every_n_epoch', 'proto_split_density_threshold',\n",
    "                                 'proto_remove_density_threshold', 'repulsion_loss_margin',\n",
    "                                 'seed']).cumcount()\n",
    "\n",
    "# Map result_index to coverage levels\n",
    "coverage_level_mapping = {0: 90, 1: 50, 2: 10}\n",
    "df['coverage_level'] = df['result_index'].map(coverage_level_mapping)\n",
    "\n",
    "# Define hyperparameter columns\n",
    "hyperparameter_cols = ['add_remove_every_n_epoch', 'proto_split_density_threshold',\n",
    "                       'proto_remove_density_threshold', 'repulsion_loss_margin']\n",
    "\n",
    "group_cols = hyperparameter_cols + ['coverage_level']\n",
    "\n",
    "# Compute the average and standard deviation for each hyperparameter setting across seeds\n",
    "grouped = df.groupby(group_cols).agg({\n",
    "    'cov_value': ['mean', 'std'],\n",
    "    'PINAW_value': ['mean', 'std'],\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "grouped.columns = ['_'.join(col).strip('_') for col in grouped.columns.values]\n",
    "\n",
    "# Pivot the dataframe to get coverage levels as columns\n",
    "pivoted = grouped.pivot(index=hyperparameter_cols,\n",
    "                        columns='coverage_level',\n",
    "                        values=['cov_value_mean', 'cov_value_std', 'PINAW_value_mean', 'PINAW_value_std'])\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "pivoted.columns = ['{}_{}'.format(col[0], int(col[1]) / 100) for col in pivoted.columns]\n",
    "\n",
    "# Reset the index to turn hyperparameter_cols back into columns\n",
    "pivoted = pivoted.reset_index()\n",
    "\n",
    "# Rename the columns to match the desired format\n",
    "col_rename = {\n",
    "    'cov_value_mean_0.9': 'cov(0.9)',\n",
    "    'cov_value_mean_0.5': 'cov(0.5)',\n",
    "    'cov_value_mean_0.1': 'cov(0.1)',\n",
    "    'cov_value_std_0.9': 'cov_std(0.9)',\n",
    "    'cov_value_std_0.5': 'cov_std(0.5)',\n",
    "    'cov_value_std_0.1': 'cov_std(0.1)',\n",
    "    'PINAW_value_mean_0.9': 'pinaw(0.9)',\n",
    "    'PINAW_value_mean_0.5': 'pinaw(0.5)',\n",
    "    'PINAW_value_mean_0.1': 'pinaw(0.1)',\n",
    "    'PINAW_value_std_0.9': 'pinaw_std(0.9)',\n",
    "    'PINAW_value_std_0.5': 'pinaw_std(0.5)',\n",
    "    'PINAW_value_std_0.1': 'pinaw_std(0.1)',\n",
    "}\n",
    "\n",
    "pivoted.rename(columns=col_rename, inplace=True)\n",
    "\n",
    "# Reorder columns if necessary\n",
    "desired_order = hyperparameter_cols + [\n",
    "    'cov(0.9)', 'cov_std(0.9)', 'pinaw(0.9)', 'pinaw_std(0.9)',\n",
    "    'cov(0.5)', 'cov_std(0.5)', 'pinaw(0.5)', 'pinaw_std(0.5)',\n",
    "    'cov(0.1)', 'cov_std(0.1)', 'pinaw(0.1)', 'pinaw_std(0.1)'\n",
    "]\n",
    "pivoted = pivoted.reindex(columns=desired_order)\n",
    "\n",
    "# Now, 'pivoted' DataFrame has the desired format\n",
    "# Set the coverage threshold range\n",
    "coverage_target = 0.9\n",
    "coverage_threshold = 0.03\n",
    "\n",
    "# Filter rows where 'cov(0.9)' is within the desired range\n",
    "filtered = pivoted[(pivoted['cov(0.9)'] >= (0.9 - coverage_threshold)) & \n",
    "                   (pivoted['cov(0.9)'] <= (0.9 + coverage_threshold)) & \n",
    "                   (pivoted['cov(0.5)'] >= (0.5 - coverage_threshold)) & \n",
    "                   (pivoted['cov(0.5)'] <= (0.5 + coverage_threshold)) &\n",
    "                   (pivoted['cov(0.1)'] >= (0.1 - coverage_threshold)) & \n",
    "                   (pivoted['cov(0.1)'] <= (0.1 + coverage_threshold))]\n",
    "\n",
    "# Find the row with the minimum 'pinaw(0.9)' within the filtered DataFrame\n",
    "best_row = filtered.iloc[filtered['pinaw(0.9)'].argmin()]\n",
    "\n",
    "print(f\"{best_row['cov(0.9)']:.2f}, {best_row['cov_std(0.9)']:.2f} (0.9)\")\n",
    "print(f\"{best_row['pinaw(0.9)']:.2f}, {best_row['pinaw_std(0.9)']:.2f} (0.9)\")\n",
    "print(f\"{best_row['cov(0.5)']:.2f}, {best_row['cov_std(0.5)']:.2f} (0.5)\")\n",
    "print(f\"{best_row['pinaw(0.5)']:.2f}, {best_row['pinaw_std(0.5)']:.2f} (0.5)\")\n",
    "print(f\"{best_row['cov(0.1)']:.2f}, {best_row['cov_std(0.1)']:.2f} (0.1)\")\n",
    "print(f\"{best_row['pinaw(0.1)']:.2f}, {best_row['pinaw_std(0.1)']:.2f} (0.1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/halil/max_quantile/logs/White_Wine/seed_0/voronoi/softlabelbased/20240927-140859\n"
     ]
    }
   ],
   "source": [
    "\n",
    "experiment_path = df[(df[hyperparameter_cols] == best_row[hyperparameter_cols].values).all(axis=1)][\"experiment_path\"]\n",
    "\n",
    "print('/home/halil/max_quantile/' + experiment_path.iloc[1][19:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/halil/max_quantile/logs/bike_sharing/seed_1/voronoi/softlabelbased/20241028-110606\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/Unconditional_1d_data/seed_0/voronoi/softlabelbased/20240928-073009'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_path.iloc[0][19:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R2CCP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
